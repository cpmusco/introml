{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image denoising with an autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this demo, we illustrate the use of convolutional networks to build an autoencoder for image denoising. We first load keras package and some other common package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get training and testing data and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the natural images cifar10 dataset from keras build-in function. For more dataset information, you can check [Keras Document](https://keras.io/datasets/). Since we just need images for denoising, image label can be ignored. And we will just use 10000 samples for training and 1000 for test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "(x_train, _), (x_test, _) = cifar10.load_data()\n",
    "x_train = x_train[:10000]\n",
    "x_test = x_test[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We rescale x_train and x_test from 0 to 1 as this works better for the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype(\"float32\")/255\n",
    "x_test = x_test.astype(\"float32\")/255\n",
    "x_train = np.reshape(x_train, (len(x_train), 32, 32, 3)) # adapt this if using `channels_first` image data format\n",
    "x_test = np.reshape(x_test, (len(x_test), 32, 32, 3)) # adapt this if using `channels_first` image data format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will generate synthetic noisy images: just apply a gaussian noise matrix with noise factor 0.5 on each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_factor = 0.2\n",
    "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) \n",
    "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because piexl values may become out of range from 0 to 1 after noise is applied, we need to clip the images between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.) \n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can display 10 original images and corresponding noisy images. First row is original images and second row is noisy images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(Nrow, Ncol, image_size, channel, *image_list):\n",
    "    plt.figure(figsize=(2*Ncol, 2*Nrow))\n",
    "    for i in range(1,Ncol+1):\n",
    "        for j in range(len(image_list)):\n",
    "            ax = plt.subplot(len(image_list), Ncol, i+j*Ncol)\n",
    "            plt.imshow(image_list[j][i].reshape(image_size, image_size, channel))\n",
    "            plt.gray()\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "    plt.show()\n",
    "plot_image(2, 10, 32, 3, x_train, x_train_noisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up an autoencoder and train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We construct a very simple auto-encoder with 2 convolution layer encoder each followed by a maxpooling layer (down sample by a factor of 2) and two convolution layer decoder, each followed by a upsampling layer, and a third conv layer that yields the denoised image. The output image have the same size as the input.  We will use batch normalization for each layer. We have found that adding drop out does not have much effect. You could try to add and evaluate the effect. Note that instead of using model.add( ) you could use the following procedures to add layers as well.\n",
    "\n",
    "For reconstructing an image, a natural choice for the activation function of the output layer would be \"linear\". However, this does not guarantee the reconstructed values would be in the desired range of 0 to 1. Although we could clip the output image,  through experiments, we have found that using a sigmoid activation function is better. This may in part because it guarantees the output is in the range of 0 to 1. With the same number of epochs, using \"linear\" activiation yielded more blury images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, UpSampling2D, Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "\n",
    "K.clear_session()\n",
    "input_img = Input(shape=(32,32,3))\n",
    "x = Conv2D(16, (3,3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPool2D((2,2), padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "# x = Dropout(0.25)(x)\n",
    "x = Conv2D(32, (3,3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPool2D((2,2), padding='same', name='encoded_layer')(x)\n",
    "\n",
    "x = BatchNormalization()(encoded)\n",
    "# x = Dropout(0.25)(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = BatchNormalization()(x)\n",
    "# x = Dropout(0.25)(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = BatchNormalization()(x)\n",
    "# x = Dropout(0.25)(x)\n",
    "decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "autoencoder = Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use summary() function to see model detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, to train the network, we have to select an optimizer and a loss function. We select the mean_squared_error loss and the \"adam\" optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "opt = optimizers.Adam(lr=0.01)\n",
    "autoencoder.compile(optimizer=opt, loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now fit our model using x_train_noisy as input, and x_train as output. Because it takes times to train, we will run a small number of epochs. Because our validation set has a small size, the validation error may not be a reliable measure of test performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = autoencoder.fit(x_train_noisy, x_train,\n",
    "                epochs=3,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test_noisy, x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see how the denoised images look. First row is original images, second row is noisy images, and third row shows corresponding denoised images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs = autoencoder.predict(x_test_noisy)\n",
    "plot_image(3, 10, 32, 3, x_test, x_test_noisy, decoded_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we only run 3 epochs and the training set is relatively small,  the loss is still large. The denoised images look very blurred. If you want to get a more acceptable model to denoise, more epochs and more samples are needed. The following trains the model using 100 epochs. This model is saved, and can be loaded using the load_model() tool. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = autoencoder.fit(x_train_noisy, x_train,\n",
    "                epochs=97,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test_noisy, x_test))\n",
    "\n",
    "autoencoder.save(\"cifar_autoencoder_100epochs.h5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us plot the training curves. We can see that although the training loss continuously decreasing, the validation loss is not stable. This is mainly because we used a very small validation set. A larger validation set should lead to a more stable loss curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss curves\n",
    "# Skip this if you you only trained for 3 epochs.\n",
    "\n",
    "epochsn=np.arange(4, 101)\n",
    "plt.plot(epochsn,hist.history['loss'])\n",
    "plt.plot(epochsn,hist.history['val_loss'])\n",
    "plt.xlim((4, 100))\n",
    "\n",
    "plt.grid()\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Curve')\n",
    "plt.legend(['Training', 'Validation'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the denoising performance visually "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "autoencoder = load_model('./cifar_autoencoder_100epochs.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see how the denoised images look with this model. We plot denoised images from both the testing set and the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "decoded_test_imgs = autoencoder.predict(x_test_noisy[:11])\n",
    "plot_image(3, 10, 32, 3, x_test, x_test_noisy, decoded_test_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_train_imgs = autoencoder.predict(x_train_noisy[:11])\n",
    "# decoded_imgs = autoencoder.predict(x_test_noisy)\n",
    "plot_image(3, 10, 32, 3, x_train, x_train_noisy, decoded_train_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that  with this pretrained model, denoised images for those in training data are noticeably better. For better results, we need to train with more data. Also, using MSE alone often lead to blurred images. Using a advasarial discriminator loss (as in Generative Advasarial Network) in addition to MSE can help to reduce blurring. You can look into those on your own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do the encoded feature maps look?\n",
    "Let us take a look at encoded image of a test sample. First let us plot an noisy image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_original = x_test[1]\n",
    "test_sample = x_test_noisy[1]\n",
    "test_denoised = decoded_test_imgs[1]\n",
    "\n",
    "plt.subplots(1,3)\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(test_original)\n",
    "plt.title('Original')\n",
    "plt.axis('off')\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(test_noisy)\n",
    "plt.title('Noisy')\n",
    "plt.axis('off')\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(test_denoised)\n",
    "plt.title('Denoised')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then put test sample into model and plot encoded noised image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model input should have 4 dimension: batch_size * length * width * channel\n",
    "test_sample_expanded = np.expand_dims(test_sample, axis=0)\n",
    "layer_name = 'encoded_layer'\n",
    "encout_output_layer = Model(inputs=autoencoder.input, outputs=autoencoder.get_layer(layer_name).output)\n",
    "encode_image = encout_output_layer.predict(test_sample_expanded)[0]\n",
    "n = 8 \n",
    "plt.figure(figsize=(20, 8))\n",
    "for i in range(0, 8):\n",
    "    ax = plt.subplot(4, n, i+1)\n",
    "    plt.imshow(encode_image[:,:,i].reshape(8, 8))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    ax = plt.subplot(4, n, i+n+1)\n",
    "    plt.imshow(encode_image[:,:,i+n].reshape(8, 8))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    ax = plt.subplot(4, n, i+2*n+1)\n",
    "    plt.imshow(encode_image[:,:,i+2*n].reshape(8, 8))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    ax = plt.subplot(4, n, i+3*n+1)\n",
    "    plt.imshow(encode_image[:,:,i+3*n].reshape(8, 8))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that some feature maps are completely zero. This suggests that we may not need 32 channels for the encoded features. You may wonder how the decoder generates the denoised image from these features .... That is the mystry of deep network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
