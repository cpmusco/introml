{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent Optimization\n",
    "\n",
    "In the ``demo_breast_cancer.ipynb``, we used the `sklearn` built-in `LogisticRegression` class to find the weights for the logistic regression problem.   The `fit` routine in that class has an *optimizer* to select the weights to best match the data.  To understand how that optimizer works, in this demo, we will build a very simple gradient descent optimizer from scratch.  You will learn to:\n",
    "* Compute the gradients of a loss function and implement the gradient calculations in python\n",
    "* Implement a simple gradient descent optimizer\n",
    "* Visualize the effect of the learning rate in gradient descent\n",
    "* Implement an adaptive learning rate algorithm\n",
    "* Add regularization to the loss minimization problem\n",
    "* Try out different black-box optimizers in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Breast Cancer Data\n",
    "\n",
    "We first load the standard packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next load the data from the [breast cancer demo](../logistic/breast_cancer.ipynb).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['id','thick','size_unif','shape_unif','marg','cell_size','bare',\n",
    "         'chrom','normal','mit','class']\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/' +\n",
    "                 'breast-cancer-wisconsin/breast-cancer-wisconsin.data',\n",
    "                names=names,na_values='?',header=None)\n",
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the breast cancer demo, we create a data matrix `X` of various features of the breast cancer sample.  The response vector `y` is a binary indicating if each sample is benign or malignant.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the predictors\n",
    "xnames = ['thick','size_unif','shape_unif','marg','cell_size','bare',\n",
    "         'chrom','normal','mit']\n",
    "Xraw = np.array(df[xnames])\n",
    "# As usual, let's also append an all ones vector onto X to serve as the intercept feature\n",
    "X = np.concatenate((np.ones((Xraw.shape[0],1)),Xraw),axis=1)\n",
    "\n",
    "# Get the response.  Convert to a zero-one indicator \n",
    "yraw = np.array(df['class'])\n",
    "BEN_VAL = 2   # value in the 'class' label for benign samples\n",
    "MAL_VAL = 4   # value in the 'class' label for malignant samples\n",
    "y = (yraw == MAL_VAL).astype(int) # now y has values of 0,1 \n",
    "Iben = (y==0)\n",
    "Imal = (y==1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to learn the classification rule to predict `y` from `X`.  We will do so with logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the Gradient and Loss Function\n",
    "\n",
    "Recall that training a logistic function means finding a weight vector $\\beta$ for the classification rule:\n",
    "* Predict 1 for data vector $\\vec{x}$ if $\\frac{1}{1 + e^{-\\vec{x}^T\\vec{\\beta}}} > 1/2$, i.e. if $\\vec{x}^T\\vec{\\beta} > 0$. \n",
    "* Predict 0 for data vector $\\vec{x}$ if $\\frac{1}{1 + e^{-\\vec{x}^T\\vec{\\beta}}} \\leq 1/2$, i.e. if $\\vec{x}^T\\vec{\\beta} \\leq 0$.\n",
    "\n",
    "Let $h_{\\vec{\\beta}}(\\vec{x}) = \\frac{1}{1 + e^{-\\vec{x}^T\\vec{\\beta}}}$. To find $\\beta$, we minimize the cross-entropy loss (aka the logistic loss):\n",
    "$$\n",
    "L(\\vec{\\beta}) = - \\sum_{i=1}^n y_i \\log(h_{\\vec{\\beta}}(\\vec{x}_i)) + (1-y_i) \\log(1-h_{\\vec{\\beta}}(\\vec{x}_i)).\n",
    "$$\n",
    "As show in class we have\n",
    "$$\n",
    "\\nabla L(\\vec{\\beta}) = \\mathbf{X}^T(h_{\\vec{\\beta}}(\\mathbf{X}) - y)\n",
    "$$\n",
    "where $h_{\\vec{\\beta}}(\\mathbf{X})$ denotes the vector obtained by applying $h$ to every row in $\\mathbf{X}$. \n",
    "    \n",
    "    \n",
    "We will first write a function to compute `L` and its gradient `Lgrad`. One issue with the gradient is that directly computing $L$ using the expression above can be *numerically unstable*. A student brought up this issue in lecture: essentially what can happen is you end up taking logs of numbers very close to zero and Python will return NaNs due to issues with using finite precision arithmetic. To deal with this problem, we write down an alternative expression for `L` which is *mathematically equivalent* but can be computed more accurately in finite precision arithmetic:\n",
    "$$\n",
    "L(\\vec{\\beta}) = \\sum_{i=1}^n (1-y_i)(\\vec{x}_i^T\\vec{\\beta}) - \\log(h_{\\vec{\\beta}}(\\vec{x}_i)).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Leval(beta,X,y):\n",
    "    \"\"\"\n",
    "    Compute the loss and gradient given beta,X,y\n",
    "    \"\"\"\n",
    "    z = X@beta\n",
    "    h = 1/(1+np.exp(-z))\n",
    "    L = np.sum((1-y)*z - np.log(h))\n",
    "\n",
    "    # Gradient\n",
    "    Lgrad = (X.T)@(h-y)\n",
    "    return L, Lgrad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test our function on a random parameter vector $\\vec{\\beta}_0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some random point\n",
    "p = X.shape[1]\n",
    "beta0 = np.random.randn(p)\n",
    "\n",
    "# Call the function\n",
    "L, Lgrad = Leval(beta0,X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's not ideal that the loss function `L(beta,X,y)` depends on the parameters `X` and `y`.  Most numerical optimizers expect a function that only depends on `beta`. We can acheive this by using a Python `lambda` function to fix the parameters `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function with X,y fixed\n",
    "Leval_param = lambda beta: Leval(beta,X,y)\n",
    "\n",
    "# You can now pass a parameter like w0\n",
    "L0, Lgrad0 = Leval_param(beta0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the gradient\n",
    "\n",
    "Whenever you write a function for computing a gradient, it is very important to test if the gradient is correct.  This is the number one reason people's code does not work with numerical optimizers.  The simplest method is to take two points `beta0` and `beta1` that are close to one another and then verify that:\n",
    "$$\n",
    "L(\\vec{\\beta}_1) - L(\\vec{\\beta}_0) \\approx \\langle \\nabla L(\\vec{\\beta}_0), \\vec{\\beta}_1 - \\vec{\\beta}_0\\rangle.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a random initial point\n",
    "p = X.shape[1]\n",
    "beta0 = np.random.randn(p)\n",
    "\n",
    "# Perturb the point\n",
    "step = 1e-6\n",
    "beta1 = beta0 + step*np.random.randn(p)\n",
    "\n",
    "# Measure the function and gradient at w0 and w1\n",
    "L0, Lgrad0 = Leval_param(beta0)\n",
    "L1, Lgrad1 = Leval_param(beta1)\n",
    "\n",
    "# Predict the amount the function should have changed based on the gradient\n",
    "dL_est = Lgrad0.T@(beta1-beta0)\n",
    "\n",
    "# Print the two values to see if they are close\n",
    "print(\"Actual L1-L0    = %12.4e\" % (L1-L0))\n",
    "print(\"Predicted L1-L0 = %12.4e\" % dL_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the two agree well. You can run the block multiple times to get different answers (depending on the random choice of $\\beta_0$, but you always see agreement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Simple Gradient Descent Optimizer\n",
    "\n",
    "Now, we build a simple gradient descent optimizer function with a fixed learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_opt_simp(grad_func, beta0, lr=1e-3,nit=1000):\n",
    "    \"\"\"\n",
    "    Simple gradient descent optimization\n",
    "    \n",
    "    grad_func:  A function that returns the objective function L, and its gradient Leval\n",
    "    beta0:  Initial estimate for parameters beta\n",
    "    lr:     learning rate\n",
    "    nit:    Number of iterations\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create history dictionary for tracking progress per iteration.\n",
    "    # This isn't necessary if you just want the final answer, but it \n",
    "    # is useful for debugging\n",
    "    hist = {'beta': [], 'L': []}\n",
    "    \n",
    "    # initialize\n",
    "    beta = beta0\n",
    "    \n",
    "    # Loop over iterations\n",
    "    for it in range(nit):\n",
    "\n",
    "        # Evaluate the function and gradient\n",
    "        L, Lgrad = grad_func(beta)\n",
    "\n",
    "        # Take a gradient step\n",
    "        beta = beta - lr*Lgrad\n",
    "        \n",
    "         # Save history\n",
    "        hist['L'].append(L)\n",
    "        hist['beta'].append(beta)\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    for elem in ('L', 'beta'):\n",
    "        hist[elem] = np.array(hist[elem])\n",
    "    return beta, L, hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now run the gradient descent starting from a initial condition of $\\vec{\\beta}_0 = \\vec{0}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initial condition\n",
    "beta0 = np.zeros(p)\n",
    "\n",
    "# Parameters\n",
    "nit = 2000\n",
    "lr = 1e-5\n",
    "\n",
    "# Run the gradient descent\n",
    "beta, L, hist = grad_opt_simp(Leval_param, beta0, lr=lr, nit=nit)\n",
    "\n",
    "# Plot the training loss\n",
    "t = np.arange(nit)\n",
    "plt.plot(t, hist['L'])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can measure the accuracy of the final estimate by creating a predict method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X,beta):\n",
    "    z = X@beta\n",
    "    yhat = (z > 0)\n",
    "    return (1*yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "yhat = predict(X,beta)\n",
    "acc = np.mean(yhat == y)\n",
    "print(\"Train accuracy = %f\" % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not quite as good as the accuracy for the `sklearn` method from the demo, which was about 98.5%.  The reason is that the learning rate was somewhat slow and we didn't yet fully converge.\n",
    "\n",
    "To see the effect of the learning rate, the code below tries different learning rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate values to test\n",
    "lr_test = [1e-5,1e-4,1e-3]\n",
    "ntest = len(lr_test)\n",
    "\n",
    "# Strings for the legend\n",
    "leg_str = []\n",
    "\n",
    "beta0 = np.zeros(p)\n",
    "for i in range(ntest):\n",
    "    # Run the optimizer\n",
    "    beta, L, hist = grad_opt_simp(Leval_param, beta0, lr=lr_test[i], nit=nit)    \n",
    "    \n",
    "    # Plot the results\n",
    "    plt.semilogy(t, hist['L'])\n",
    "    leg_str.append(\"lr=%12.2e\" % lr_test[i])\n",
    "    \n",
    "    # Measure the train accuracy\n",
    "    yhat = predict(X,beta)\n",
    "    acc = np.mean(yhat == y)\n",
    "    print(\"lr=%12.2e  Train accuracy = %f\" % (lr_test[i], acc))\n",
    "    \n",
    "plt.grid()\n",
    "plt.legend(leg_str, loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that increasing the learning rate, speeds the convergence time, but the optimization is beginning to go unstable. It recovers from this instability for learning rate `1e-3`, but try running with rate `1e-2` to see more of an issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptive Step Size\n",
    "\n",
    "The above example shows that gradient descent is sensitive to the step size.  We now consider a variant of gradient descent with an adaptive step-size using the Armijo rule discussed in class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_opt_adapt(grad_func, beta0, nit=2000, lr_init=1e-3):\n",
    "    \"\"\"\n",
    "    Gradient descent optimization with adaptive step size\n",
    "    \n",
    "    feval:  A function that returns f, fgrad, the objective\n",
    "            function and its gradient\n",
    "    beta0:  Initial estimate\n",
    "    nit:    Number of iterations\n",
    "    lr:     Initial learning rate\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set initial point\n",
    "    beta = beta0\n",
    "    lr = lr_init\n",
    "    \n",
    "    # Create history dictionary for tracking progress per iteration.\n",
    "    # This isn't necessary if you just want the final answer, but it \n",
    "    # is useful for debugging\n",
    "    hist = {'lr': [], 'beta': [], 'L': []}\n",
    "\n",
    "    L,Lgrad = grad_func(beta0)\n",
    "    for it in range(nit):\n",
    "\n",
    "        # Take a gradient step\n",
    "        beta1 = beta - lr*Lgrad\n",
    "\n",
    "        # Evaluate the test point by computing the objective function, L1,\n",
    "        # at the test point and the predicted decrease, df_est\n",
    "        L1, Lgrad1 = grad_func(beta1)\n",
    "        df_est = Lgrad.T@(beta1-beta)\n",
    "        \n",
    "        # Check if test point passes the Armijo condition\n",
    "        alpha = 0.5\n",
    "        if (L1-L < alpha*df_est) and (L1 < L):\n",
    "            # If descent is sufficient, accept the point and increase the learning rate\n",
    "            lr = lr*2\n",
    "            L = L1\n",
    "            Lgrad = Lgrad1\n",
    "            beta = beta1\n",
    "        else:\n",
    "            # Otherwise, decrease the learning rate\n",
    "            lr = lr/2            \n",
    "            \n",
    "        # Save history\n",
    "        hist['L'].append(L)\n",
    "        hist['lr'].append(lr)\n",
    "        hist['beta'].append(beta0)\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    for elem in ('L', 'lr', 'beta'):\n",
    "        hist[elem] = np.array(hist[elem])\n",
    "    return beta, L, hist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now run the new optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta0 = np.zeros(p)\n",
    "nit = 2000\n",
    "beta, L, hist = grad_opt_adapt(Leval_param, beta0, nit=nit)\n",
    "\n",
    "t = np.arange(nit)\n",
    "plt.subplot(2,1,1)\n",
    "plt.semilogy(t, hist['L'])\n",
    "plt.grid()\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.loglog(t, hist['lr'])\n",
    "plt.grid()\n",
    "plt.ylabel('Learning rate')\n",
    "plt.xlabel('Iteration')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we measure the accuracy and see that we performed as well as the best fixed step size used above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = predict(X,beta)\n",
    "acc = np.mean(yhat == y)\n",
    "print(\"Train accuracy = %f\" % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2 Regularization\n",
    "\n",
    "Just as for linear regression, given enough features, logsitic regression can be prone to overfitting. In such cases, it often make sense to add regularization when training. In particular, instead of minimizing:\n",
    "$$\n",
    "L(\\mathbf{\\vec{\\beta}}) =\\sum_{i=1}^n (1-y_i)(\\vec{x}_i^T\\vec{\\beta}) - \\log(h_{\\vec{\\beta}}(\\vec{x}_i)).\n",
    "$$\n",
    "we might use $\\ell_2$ regularization and choose $\\beta$ to minimize\n",
    "$$\n",
    "L_R(\\vec{\\beta}) = L(\\vec{\\beta}) + \\lambda \\|\\vec{\\beta}\\|_2^2\n",
    "$$\n",
    "for some regularization parameter $\\lambda$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function which evaluates the regularized loss `Lr` for parameters `beta` and also computes the gradient $\\nabla L_R(\\vec{\\beta})$ at `beta`. You will have to derive an expression for this gradient to correctly implement your function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Leval_reg(beta,X,y,lamb):\n",
    "    \"\"\"\n",
    "    Compute the regularized loss and gradient given beta, X, y, and regularization parameter lamb\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    # Lr =\n",
    "    # Lrgrad\n",
    "\n",
    "    return Lr, Lrgrad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we did above for the unregularized loss, write code to test your gradient computation. Run your test for `lamb` equals `0`,`1`,`10`,`100` and print output which confirms the accuracy of your gradient in all cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `lamb` equals `0`,`1`,`10`,`100` use `grad_opt_adapt` run for `2000` iterations with $\\vec{\\beta}_0 = \\vec{0}$ to find a parameter vector $\\beta$ which approximately minimizes $L_R(\\beta)$. For each regularization level, print the train accuracy achieved when using the optimal parameters. Note that we expect the **train accuracy to decrease** as the regularization parameter increases. Regularization often helps **test accuracy to increase**, but for this lab we're keeping things simple without a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "\n",
    "# These are the outputs I got:\n",
    "# lamb = 0, Train accuracy = 0.970717\n",
    "# lamb = 1, Train accuracy = 0.969253\n",
    "# lamb = 10, Train accuracy = 0.959004\n",
    "# lamb = 100, Train accuracy = 0.920937"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel Logistic Regression, Linear Kernel\n",
    "\n",
    "Logistic regression works nicely with non-linear kernels, which can significantly improve its accuracy for certain problems. We will see an example in our next lab on classifying MNIST images. \n",
    "\n",
    "To use logistic regression with a kernel, our first step was to reparameterize the logistic loss function by replacing $\\vec{\\beta}\\in \\mathbb{R}^d$ with $\\mathbf{X}^T\\vec{\\alpha}$ where $\\vec{\\alpha}\\in \\mathbb{R}^n$ is a new parameter vector.  \n",
    "\n",
    "Our loss becomes:\n",
    "$$\n",
    "L(\\vec{\\alpha}) =\\sum_{i=1}^n (1-y_i)(\\vec{x}_i^T\\mathbf{X}^T\\vec{\\alpha}) - \\log(h_{\\mathbf{X}^T\\vec{\\alpha}}(\\vec{x}_i)).\n",
    "$$\n",
    "The regularized loss becomes:\n",
    "$$\n",
    "L_R(\\vec{\\alpha}) = L(\\vec{\\alpha}) + \\lambda \\|\\vec{X}^T\\vec{\\alpha}\\|_2^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function which evaluates the regularized loss `Lr` for parameters `alpha` and also computes the gradient $\\nabla L_R(\\vec{\\alpha})$ at `alpha`. Again, you will have to derive an expression for this gradient to implement your function. \n",
    "\n",
    "**Note**: We are not doing anything with a non-linear kernel yet, but we will in the next lab! Here we are just going through the first step of reformulating our logistic regression model to eventually use different kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Leval_reg_linear_kernel(alpha,X,y,lamb):\n",
    "    \"\"\"\n",
    "    Compute the regularized loss and gradient given beta, X, y, and regularization parameter lamb\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    # Lr =\n",
    "    # Lrgrad\n",
    "\n",
    "    return Lr, Lrgrad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though our reformuation leads to an equivalent loss function and regularization term, the updates performed by the gradient descent optimizer are not exactly the same. In fact, after reparameterization, we can see that gradient descent converges much more slowly to a solution. \n",
    "\n",
    "To see this yourself, run `grad_opt_adapt` for `5000` steps to minimize the regularized logistic regression loss for data `X`,`y` with `lamb = 10`, using both the original formulation (involving `beta`) and the reparameterized formulation, involving `alpha`. Plot the history of how the loss function decreases over time a single plot with two lines: one for the original formulation and one for the reparameterization. Include axis labels and a legend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nit = 5000\n",
    "l = 10\n",
    "beta0 = np.zeros(X.shape[1])\n",
    "alpha0 = np.zeros(X.shape[0])\n",
    "\n",
    "# TODO\n",
    "# Optimize alpha via gradient descent\n",
    "# Optimize beta via gradient descent\n",
    "# Generate plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After `5000` steps, what is the minimum regularized objective function value acheived for each formulation of the problem? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO \n",
    "# Print minimum objective values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately, when gradient descent converges slowly, there are other first-order optimization algorithms that can be used in its place, and often converge much faster. Here we will try using some built-in optimization methods for the `scipy` library in Python. In particular, we use the function `scipy.optimize.minimize` which is documented [here](https://docs.scipy.org/doc/scipy-0.13.0/reference/generated/scipy.optimize.minimize.html).\n",
    "\n",
    "This function takes many inputs. The two most important ones are the `fun` and `jac` arguments, which should be passed Python functions for 1) evaluating the function we want to minimize at an point and 2) evaluating the gradient of the function at any point. `jac` is short for \"Jacobian\" which is a generalization of the gradient for multi-output functions. Since we're dealing with a loss function which just has one output, the Jacobian is equal to the gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code below for minimizing the reparameterized regularized loss using the [\"BFGS\" algorithm](https://en.wikipedia.org/wiki/Broyden%E2%80%93Fletcher%E2%80%93Goldfarb%E2%80%93Shanno_algorithm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 10\n",
    "# function for computing regularized loss\n",
    "f = lambda alpha: Leval_reg_linear_kernel(alpha,X,y,l)[0]\n",
    "# function for computing gradient of regularized loss\n",
    "g = lambda alpha: Leval_reg_linear_kernel(alpha,X,y,l)[1]\n",
    "alpha0 = np.zeros(X.shape[0])\n",
    "# res stores the result of scipy.optimize.minimize, which contains a number of pieces of information\n",
    "res = scipy.optimize.minimize(f, alpha0, args=(), method='BFGS', jac=g) \n",
    "# we're most interest in the minimizing argument, which can be obtained via res.x\n",
    "alpha = res.x\n",
    "# we check the objective value obtained\n",
    "Leval_reg_linear_kernel(alpha,X,y,l)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should observe a loss much closer to minimum obtained before reparameterization (which is very close to the true minimum), and the method runs in a fraction of the time that gradient descent would have required! You can time how long the solvers take to converge using the following code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "scipy.optimize.minimize(f, alpha0, args=(), method='newton-cg', jac=g) \n",
    "elapsed = time.time() - t\n",
    "print(\"Elapsed time: \" + str(elapsed))\n",
    "alpha = res.x\n",
    "print(\"Minimum loss value: \" + str(Leval_reg_linear_kernel(alpha,X,y,l)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refering the documentation try out different algorithms for `scipy.optimize.minimize`. Find a first-order method (only requires gradients) which provides a comparable solution to `BFGS` but in less time. Note the method here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO What's a faster method for this problem? "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
