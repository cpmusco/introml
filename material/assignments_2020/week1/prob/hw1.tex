\documentclass[10pt]{article}
\usepackage{titlesec}
\usepackage{geometry}
\geometry{verbose,tmargin=.9in,bmargin=.9in,lmargin=1.0in,rmargin=1.0in}
\usepackage{amsmath,amsfonts,amsthm,amssymb}
\usepackage{url}
\usepackage{color}
\usepackage[usenames,dvipsnames,svgnames,table]{xcolor}
\usepackage[colorlinks=true, linkcolor=red, urlcolor=blue, citecolor=gray]{hyperref}
\usepackage{float}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{enumerate}
\usepackage{multicol}
\usepackage{etoolbox}

\definecolor{nyuDarkPurple}{HTML}{330662}
\definecolor{nyuOfficialPurple}{HTML}{57068c}

\newcommand{\spara}[1]{\vspace{.5em}\noindent {\large\sffamily\textcolor{nyuOfficialPurple}{#1}}}
\titleformat{\section}[hang]{\Large\sffamily\color{nyuDarkPurple}}{\thesection}{1em}{}
\titleformat{\subsection}[hang]{\large\sffamily\color{nyuDarkPurple}}{\thesection}{1em}{}
\titleformat{\subsubsection}[hang]{\normalsize\sffamily\color{gray}}{\thesection}{1em}{}

\usepackage{fancyhdr}
\pagestyle{fancy}
\lhead{\includegraphics[width=4cm]{tandon_long_color.eps}}
\rhead{\thepage}
\pagenumbering{gobble}

\setcounter{secnumdepth}{0}

% math commands
\DeclareMathOperator{\R}{\mathbb{R}}
\newcommand{\E}{\mathbb{E}}

\begin{document}
	
\begin{center}
	\normalsize
	New York University Tandon School of Engineering
	
	Computer Science and Engineering
	\medskip
	
	\large
	CS-UY 4563: Written Homework 1. 
	
	Due Thursday, February 6th, 2020, 11:59pm.
	\medskip
	
	\normalsize 
	\noindent \emph{Collaboration is allowed on this problem set, but solutions must be written-up individually. Please list the names of any collaborators at the top of your solution set, or write ``No Collaborators" if you worked alone.}
	\medskip
	
	\noindent \emph{For just this first problem set, $10\%$ extra credit will be given if solutions are typewritten (using LaTeX, Markdown, or some other mathematical formatting program).}

\end{center} 

\subsection{Problem 1: Practice Framing a Supervised Learning Problem (10pts)}
 A university admissions office wants to predict the success of students based on
their application material.  They have access to past student records to learn
a good algorithm.
\begin{enumerate}[(a)]
	\item To formulate this as a supervised learning problem,
	identify a possible target variable.  This should be some variable that measures success
	in a meaningful way and can be easily collected (in an automated manner) by the
	university. There is no one correct answer to this problem.
	\item Is the target variable continuous or discrete-valued?
	\item State one possible variable that can act as the predictor for the target
	variable you chose in part (a).
	\item Without looking at data, would a linear model for the data be reasonable?
	If so, what sign do you expect the slope to be? If note, what might be a better model?
\end{enumerate}

\subsection{Problem 2: Practice Minimizing a Loss Function (10pts)}
Consider a linear model of the form
\begin{align*}
f_{\beta}(x) = \beta x,
\end{align*}
which is the same as the linear model we saw in class, but with the intercept forced to zero.  Such models are used when we want to force the predicted value $f_{\beta}(x)=0$ when
$x=0$.  For example, if we are modeling $y=$ output power of a motor
vs.\ $x=$ the input power, we would expect $x=0 \Rightarrow y=0$.
\begin{enumerate}[(a)]
	\item Given data $(x_1,y_1), \ldots, (x_n,y_n)$,
	write the equation for a loss function which measures prediction accuracy using the sum-of-squared distances between the predicted values and target values. 
	
	\item Derive an expression for the $\beta$ that minimizes this loss function. Do you get the same expression that we got for $\beta_1$ in the full linear model? 
\end{enumerate}


\subsection{Problem 3: Building Intuition about Different Loss Functions. (10pts)}
Suppose we have data  $y_1, \ldots, y_n \in \mathbb{R}$ and we want to choose some value $m \in \R$ which is ``most representative'' of our dataset. This is sometimes called the ``central tendency'' problem in statistics. A machine learning approach to this problem would measure how representative $m$ is of the data using a loss function. 
\begin{enumerate}[(a)]
	\item Consider the loss function $L(m) = \sum_{i=1}^n (y_i - m)^2$. Show that $L(m)$ is minimized by setting $m = \bar{y}$, where $\bar{y} = \frac{1}{n}\sum_{i=1}^n y_i$ is the \emph{mean} of our data. 
	\item Consider the loss function $L(m) = \max_i|y_i - m|$. What value of $m$ minimizes this loss? Hint: Using derivatives will not help here -- try just thinking about the minimization problem directly.

	\item \textbf{Bonus (5pts):} Consider the loss function $L(m) = \sum_{i=1}^n |y_i - m|$. Show that $L(m)$ is minimized by setting $m$ to the \emph{median} of the data. 

	
	\item In a few short sentences, discuss when you might prefer each of the three losses above. Is the median typically considered a more ``robust'' measure of central tendency than the mean? Why?
\end{enumerate}

\subsection{Problem 4: Practice with Non-linear Transformations.}
(\textbf{Hint:} Take a look at the example at the end of my Lecture 2 notes)
\vspace{.5em}

 A medical researcher wants to model, $f(t)$, the concentration
of some chemical in the blood
over time. She believes the concentration should decay exponentially in that
\begin{align}
\label{eq:zexp}
f(t) = z_0 e^{-\alpha t},
\end{align}
for some parameters $z_0$ and $\alpha$.
To confirm this model, and to estimate the parameters $z_0,\alpha$,
she collects a large number of time-stamped samples $(t_i,c_i)$, $i=1,\ldots,n$, where $c_i$ is the measured concentration at time $t_i$.
Unfortunately, the model \eqref{eq:zexp} is non-linear, so she can't directly apply
the linear regression formula to estimate $z_0$ and $\alpha$.
\begin{enumerate}[(a)]
	\item  Taking logarithms, show that we can transform our training data so that the conjectured relationship between predictor and target variables is in fact linear. 
	\item Write pseudocode (or actual Python) for how you might estimate $z_0$ and $\alpha$ using this transformation. 
	

\end{enumerate}




\end{document}